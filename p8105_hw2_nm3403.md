Data Science HW 2
================
Nandini M
2023-10-3

Load in the necessary libraries

# Problem 1

We clean the 538 `pols` data, which provides information on the number
of national politicians who are democratic or republican at any given
time. There are some values for which `prez_gop` is `2` – these are
months in which Ford became President following Nixon’s resignation. In
the new `president` variable created as part of our data cleaning, we
code these as `gop` (same as values when `prez_gop` is `1`).

``` r
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols = 
  read_csv("./Data/fivethirtyeight_datasets/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
```

    ## Rows: 822 Columns: 9
    ## -- Column specification --------------------------------------------------------
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## i Use `spec()` to retrieve the full column specification for this data.
    ## i Specify the column types or set `show_col_types = FALSE` to quiet this message.
    ## Joining with `by = join_by(month_num)`

We also clean the 538 `snp` data, which contains information related to
Standard & Poor’s stock market index.

``` r
snp = 
  read_csv(
    "./Data/fivethirtyeight_datasets/snp.csv",
    col_types = cols(date = col_date(format = "%m/%d/%y"))) |>
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    year = if_else(year > 2023, year - 100, year)) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, close) 
```

    ## Joining with `by = join_by(month_num)`

Finally, we tidy the `unemployment` data so that it can be merged with
the `pols` and `snp` datasets.

``` r
unemployment = 
  read_csv("./Data/fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

    ## Rows: 68 Columns: 13
    ## -- Column specification --------------------------------------------------------
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## i Use `spec()` to retrieve the full column specification for this data.
    ## i Specify the column types or set `show_col_types = FALSE` to quiet this message.
    ## Joining with `by = join_by(month_abb)`

Now we merge the three datasets!

``` r
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)
```

    ## Joining with `by = join_by(year, month)`
    ## Joining with `by = join_by(year, month)`

``` r
str(data_538)
```

    ## tibble [822 x 13] (S3: tbl_df/tbl/data.frame)
    ##  $ year        : num [1:822] 1947 1947 1947 1947 1947 ...
    ##  $ month       : chr [1:822] "January" "February" "March" "April" ...
    ##  $ month_num   : int [1:822] 1 2 3 4 5 6 7 8 9 10 ...
    ##  $ gov_gop     : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
    ##  $ sen_gop     : num [1:822] 51 51 51 51 51 51 51 51 51 51 ...
    ##  $ rep_gop     : num [1:822] 253 253 253 253 253 253 253 253 253 253 ...
    ##  $ gov_dem     : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
    ##  $ sen_dem     : num [1:822] 45 45 45 45 45 45 45 45 45 45 ...
    ##  $ rep_dem     : num [1:822] 198 198 198 198 198 198 198 198 198 198 ...
    ##  $ president   : chr [1:822] "dem" "dem" "dem" "dem" ...
    ##  $ month_abb   : chr [1:822] "Jan" "Feb" "Mar" "Apr" ...
    ##  $ close       : num [1:822] NA NA NA NA NA NA NA NA NA NA ...
    ##  $ unemployment: num [1:822] NA NA NA NA NA NA NA NA NA NA ...

Notice that there are some `NA` values in the `close` and `unemployment`
variables, which indicate that the value of these variables is missing
at those locations.

Let’s talk about the 538 datasets. The `pols` data has 822 observations
and 11 variables and tells us about the party affiliation distribution
(democrat or republican) for governors and senators for a given year
from years 1947 to 2015. It also tells us whether the sitting president
was a democrat or republican. The `snp` data has 787 observations and 3
variables, ranging from years 1950 to 2015. The `unemployment` data has
816 observations and 3 variables ranging from years 1948 to 2015. In
Januarys in or after 1975 in which a democrat was president, the
**average unemployment rate was 6.57**. The average unemployment rate
over the same time period in which a republican was president was 6.47.

# Problem 2

Clean the data: omit non-data entries (rows with notes / figures;
columns containing notes) using arguments in read_excel use reasonable
variable names omit rows that do not include dumpster-specific data

Create a new homes_powered variable applied to every row

``` r
# Mr.Trash Wheel data

trash_wheel = 
  read_excel("./Data/202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:M586", 
             col_names = TRUE) |> 
  janitor::clean_names() |> 
  mutate(
    new_homes_powered = (weight_tons*500)/30, # 1 ton of trash =  avg 500 kilowatts, 1 avg household = 30             
                                              # kilowatts/day
    wheel = 1
  )

trash_wheel
```

    ## # A tibble: 584 x 15
    ##    dumpster month year  date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <chr> <dttm>                    <dbl>              <dbl>
    ##  1        1 May   2014  2014-05-16 00:00:00        4.31                 18
    ##  2        2 May   2014  2014-05-16 00:00:00        2.74                 13
    ##  3        3 May   2014  2014-05-16 00:00:00        3.45                 15
    ##  4        4 May   2014  2014-05-17 00:00:00        3.1                  15
    ##  5        5 May   2014  2014-05-17 00:00:00        4.06                 18
    ##  6        6 May   2014  2014-05-20 00:00:00        2.71                 13
    ##  7        7 May   2014  2014-05-21 00:00:00        1.91                  8
    ##  8        8 May   2014  2014-05-28 00:00:00        3.7                  16
    ##  9        9 June  2014  2014-06-05 00:00:00        2.52                 14
    ## 10       10 June  2014  2014-06-11 00:00:00        3.76                 18
    ## # i 574 more rows
    ## # i 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <dbl>, new_homes_powered <dbl>, wheel <dbl>

``` r
# Professor Trash Wheel

prof_trash_wheel = 
  read_excel("./Data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:L108", 
             col_names = TRUE) |> 
  janitor::clean_names() |> 
  mutate(
    new_homes_powered = (weight_tons*500)/30,
    wheel = 2,
    sports_balls = "NA"
  )

prof_trash_wheel
```

    ## # A tibble: 106 x 15
    ##    dumpster month     year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>    <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 January   2017 2017-01-02 00:00:00        1.79                 15
    ##  2        2 January   2017 2017-01-30 00:00:00        1.58                 15
    ##  3        3 February  2017 2017-02-26 00:00:00        2.32                 18
    ##  4        4 February  2017 2017-02-26 00:00:00        3.72                 15
    ##  5        5 February  2017 2017-02-28 00:00:00        1.45                 15
    ##  6        6 March     2017 2017-03-30 00:00:00        1.71                 15
    ##  7        7 April     2017 2017-04-01 00:00:00        1.82                 15
    ##  8        8 April     2017 2017-04-20 00:00:00        2.37                 15
    ##  9        9 May       2017 2017-05-10 00:00:00        2.64                 15
    ## 10       10 May       2017 2017-05-26 00:00:00        2.78                 15
    ## # i 96 more rows
    ## # i 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, new_homes_powered <dbl>, wheel <dbl>, sports_balls <chr>

``` r
# Gwynnda

gwynnda_wheel = 
  read_excel("./Data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", range = "A2:K157", 
             col_names = TRUE) |> 
  janitor::clean_names() |> 
  mutate(
    new_homes_powered = (weight_tons*500)/30,
    wheel = 3,
    sports_balls = "NA",
    glass_bottles = "NA"
  )

gwynnda_wheel
```

    ## # A tibble: 155 x 15
    ##    dumpster month   year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>  <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 July    2021 2021-07-03 00:00:00        0.93                 15
    ##  2        2 July    2021 2021-07-07 00:00:00        2.26                 15
    ##  3        3 July    2021 2021-07-07 00:00:00        1.62                 15
    ##  4        4 July    2021 2021-07-16 00:00:00        1.76                 15
    ##  5        5 July    2021 2021-07-30 00:00:00        1.53                 15
    ##  6        6 August  2021 2021-08-11 00:00:00        2.06                 15
    ##  7        7 August  2021 2021-08-14 00:00:00        1.9                  15
    ##  8        8 August  2021 2021-08-16 00:00:00        2.16                 15
    ##  9        9 August  2021 2021-08-16 00:00:00        2.6                  15
    ## 10       10 August  2021 2021-08-17 00:00:00        3.21                 15
    ## # i 145 more rows
    ## # i 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, plastic_bags <dbl>, wrappers <dbl>,
    ## #   new_homes_powered <dbl>, wheel <dbl>, sports_balls <chr>,
    ## #   glass_bottles <chr>

Combine all three trash wheel datasets

``` r
all_wheels = 
  rbind(trash_wheel,prof_trash_wheel,gwynnda_wheel) |> 
  janitor::clean_names() |> 
  mutate(ID = case_when(wheel == 1 ~ "Mr.Trash Wheel",
                        wheel == 2 ~ "Professor Trash Wheel",
                        wheel == 3 ~ "Gwynnda Trash Wheel"))

filter(all_wheels, wheel == 3, year == 2021, month == "July") |> pull(cigarette_butts) |> sum()
```

    ## [1] 16300

The `all_wheels` dataset combines the information from the `trash_wheel`
(Mr.Trash Wheel), `prof_trash_wheel` (Professor Trash Wheel), and
`gwynnda_wheel` (Gwynnda Trash Wheel) datasets. The total number of
observations in the final dataset is 845 and the total number of
variables is 16. The `ID` variable identifies which row comes from which
of the three datasets used to make the final dataframe. Key variables
that were included in this dataset are weight of the trash in tons
(`weight_tons`), the volume of the trash in cubic yards
(`volume_cubic_yards`), the date the trash was collected (`date`), and
the number of houses that are able to be powered after converting the
weight into kilowatts of electricity (`new_homes_powered`). The dataset
also included highly prevalent forms of trash such as `wrappers`,
`cigarette_butts`, `plastic_bottles`, and `polystyrene`.

The total weight of trash collected by Professor Trash Wheel is 216.26
tons.

The total number of cigarette butts collected by Gwynnda in July of 2021
is 1.63^{4}.

# Problem 3

Import, clean, and tidy the dataset of baseline demographics

``` r
raw_demo = 
  read_csv(file = "./Data/data_mci/MCI_baseline.csv", col_names = FALSE)[-1,]
```

    ## Rows: 485 Columns: 6
    ## -- Column specification --------------------------------------------------------
    ## Delimiter: ","
    ## chr (6): X1, X2, X3, X4, X5, X6
    ## 
    ## i Use `spec()` to retrieve the full column specification for this data.
    ## i Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
demo = 
  read_csv(file = "./Data/data_mci/MCI_baseline.csv", col_names = FALSE)[-1,] |>
  janitor::row_to_names(1, remove_rows_above = FALSE) |> 
  janitor::clean_names() |> 
    mutate(
      current_age = as.numeric(current_age),
      sex = 
       case_match(
         sex, 
          "1" ~ "male", 
          "0" ~ "female"
       ),
      apoe4 = 
        case_match(
          apoe4,
          "1" ~ "Carrier",
          "0" ~ "Non-carrier"
        )
    ) |> 
  filter(age_at_onset != ".")
```

    ## Rows: 485 Columns: 6
    ## -- Column specification --------------------------------------------------------
    ## Delimiter: ","
    ## chr (6): X1, X2, X3, X4, X5, X6
    ## 
    ## i Use `spec()` to retrieve the full column specification for this data.
    ## i Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
nrow(filter(demo,sex == "female", apoe4 == "Carrier"))/nrow(filter(demo,sex == "female"))
```

    ## [1] 0.6521739

By default, R read in the first row as the column names for the dataset
during the initial import. However, this row contained information
regarding how to read the data in the table, and the actual column names
were in the second row. During cleaning, this had to be addressed first
before moving onto cleaning the individual columns otherwise it would’ve
created a more tedious process. In the read_csv() function, reading in
the column names was set to false and the first row was deleted. Then
the janitor::row_to_names() function was used to convert the new first
row of data (originally the second row) into the column names. After
these two steps, the routine steps for data cleaning were employed such
as cleaning the column names, converting the data in the `sex` and
`apoe4` columns from numeric to character and removing any rows that
didn’t meet the eligibility criteria (`age_at_onset = .`). The dataset
also included the current age of the participant (`current_age`) and
years of education (`education`), besides their sex, carrier status for
APOE4 and age at onset of MCI.

In total, 484 participants were recruited, and among these selected
individuals, 97 participants developed MCI.

The average baseline age is 65.61 years.

The proportion of women in the study that are APOE4 carriers is
`nrow(filter(demo,sex == "female", apoe4 == "Carrier"))/nrow(filter(demo,sex == "female"))`.

Import, clean, and tidy the dataset of longitudinally observed biomarker
values

comment on the steps on the import process and the features of the
dataset.

Check whether some participants appear in only the baseline or amyloid
datasets, and comment on your findings. Combine the demographic and
biomarker datasets so that only participants who appear in both datasets
are retained, and briefly describe the resulting dataset; export the
result as a CSV to your data directory
