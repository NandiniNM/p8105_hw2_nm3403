---
title: "Data Science HW 2"
author: "Nandini M"
date: "2023-10-3"
output: github_document
---

Load in the necessary libraries

```{r, echo=FALSE, message=FALSE}
# eval=FALSE -> shows code but doesn't run it
# echo=FALSE -> don't show the code
# message=FALSE -> don't show output of the code
library(tidyverse)
library(readxl)
```

# Problem 1

We clean the 538 `pols` data, which provides information on the number of national politicians who are democratic or republican at any given time. There are some values for which `prez_gop` is `2` -- these are months in which Ford became President following Nixon's resignation. In the new `president` variable created as part of our data cleaning, we code these as `gop` (same as values when `prez_gop` is `1`).

```{r clean_538_pols}
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols = 
  read_csv("./Data/fivethirtyeight_datasets/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
```

We also clean the 538 `snp` data, which contains information related to Standard & Poorâ€™s stock market index.

```{r clean_538_snp}
snp = 
  read_csv(
    "./Data/fivethirtyeight_datasets/snp.csv",
    col_types = cols(date = col_date(format = "%m/%d/%y"))) |>
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    year = if_else(year > 2023, year - 100, year)) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, close) 
```

Finally, we tidy the `unemployment` data so that it can be merged with the `pols` and `snp` datasets.

```{r clean_538_unemp}
unemployment = 
  read_csv("./Data/fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

Now we merge the three datasets!

```{r merge_538}
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)

str(data_538)
```

Notice that there are some `NA` values in the `close` and `unemployment` variables, which indicate that the value of these variables is missing at those locations.

Let's talk about the 538 datasets. The `pols` data has `r nrow(pols)` observations and `r ncol(pols)` variables and tells us about the party affiliation distribution (democrat or republican) for governors and senators for a given year from years `r pols |> pull(year) |> min()` to `r pols |> pull(year) |> max()`. It also tells us whether the sitting president was a democrat or republican. The `snp` data has `r nrow(snp)` observations and `r ncol(snp)` variables, ranging from years `r snp |> pull(year) |> min()` to `r snp |> pull(year) |> max()`. The `unemployment` data has `r nrow(unemployment)` observations and `r ncol(unemployment)` variables ranging from years `r unemployment |> pull(year) |> min()` to `r unemployment |> pull(year) |> max()`. In Januarys in or after 1975 in which a democrat was president, the **average unemployment rate was `r filter(data_538, month == "January", year >= 1975, president == "dem") |> pull(unemployment) |> mean() |> round(2)`**.  The average unemployment rate over the same time period in which a republican was president was `r filter(data_538, month == "January", year >= 1975, president == "gop") |> pull(unemployment) |> mean() |> round(2)`.

# Problem 2

## Clean the data:
* Omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel
* Use reasonable variable names
* Omit rows that do not include dumpster-specific data

## Create a new homes_powered variable applied to every row

```{r}

# Mr.Trash Wheel data

trash_wheel = 
  read_excel("./Data/202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:M586", 
             col_names = TRUE) |> 
  janitor::clean_names() |> 
  mutate(
    new_homes_powered = (weight_tons*500)/30, # 1 ton of trash =  avg 500 kilowatts, 1 avg household = 30             
                                              # kilowatts/day
    wheel = 1
  )

trash_wheel

# Professor Trash Wheel

prof_trash_wheel = 
  read_excel("./Data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:L108", 
             col_names = TRUE) |> 
  janitor::clean_names() |> 
  mutate(
    new_homes_powered = (weight_tons*500)/30,
    wheel = 2,
    sports_balls = "NA"
  )

prof_trash_wheel

# Gwynnda

gwynnda_wheel = 
  read_excel("./Data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", range = "A2:K157", 
             col_names = TRUE) |> 
  janitor::clean_names() |> 
  mutate(
    new_homes_powered = (weight_tons*500)/30,
    wheel = 3,
    sports_balls = "NA",
    glass_bottles = "NA"
  )

gwynnda_wheel
  
```

## Combine all three trash wheel datasets

```{r}

all_wheels = 
  rbind(trash_wheel,prof_trash_wheel,gwynnda_wheel) |> 
  janitor::clean_names() |> 
  mutate(ID = case_when(wheel == 1 ~ "Mr.Trash Wheel",
                        wheel == 2 ~ "Professor Trash Wheel",
                        wheel == 3 ~ "Gwynnda Trash Wheel"))

filter(all_wheels, wheel == 3, year == 2021, month == "July") |> pull(cigarette_butts) |> sum()

```

The `all_wheels` dataset combines the information from the `trash_wheel` (Mr.Trash Wheel), `prof_trash_wheel` (Professor Trash Wheel), and `gwynnda_wheel` (Gwynnda Trash Wheel) datasets. The total number of observations in the final dataset is `r nrow(all_wheels)` and the total number of variables is `r ncol(all_wheels)`. The `ID` variable identifies which row comes from which of the three datasets used to make the final dataframe. Key variables that were included in this dataset are weight of the trash in tons (`weight_tons`), the volume of the trash in cubic yards (`volume_cubic_yards`), the date the trash was collected (`date`), and the number of houses that are able to be powered after converting the weight into kilowatts of electricity (`new_homes_powered`). The dataset also included highly prevalent forms of trash such as `wrappers`, `cigarette_butts`, `plastic_bottles`, and `polystyrene`.

The total weight of trash collected by Professor Trash Wheel is `r filter(all_wheels, wheel == 2) |> pull(weight_tons) |> sum() |> round(2)` tons.

The total number of cigarette butts collected by Gwynnda in July of 2021 is `r filter(all_wheels, wheel == 3, year == 2021, month == "July") |> pull(cigarette_butts) |> sum()`.

# Problem 3

## Import, clean, and tidy the dataset of baseline demographics

```{r}

raw_demo = 
  read_csv(file = "./Data/data_mci/MCI_baseline.csv", col_names = FALSE)[-1,]

demo = 
  read_csv(file = "./Data/data_mci/MCI_baseline.csv", col_names = FALSE)[-1,] |>
  janitor::row_to_names(1, remove_rows_above = FALSE) |> 
  janitor::clean_names() |> 
    mutate(
      current_age = as.numeric(current_age),
      sex = 
       case_match(
         sex, 
          "1" ~ "male", 
          "0" ~ "female"
       ),
      apoe4 = 
        case_match(
          apoe4,
          "1" ~ "Carrier",
          "0" ~ "Non-carrier"
        )
    ) |> 
  filter(age_at_onset != ".")

```

By default, R read in the first row as the column names for the dataset during the initial import. However,
this row contained information regarding how to read the data in the table, and the actual column names were
in the second row. During cleaning, this had to be addressed first before moving onto cleaning the individual
columns otherwise it would've created a more tedious process. In the read_csv() function, reading in the column names was set to false and the first row was deleted. Then the janitor::row_to_names() function was used to convert the new first row of data (originally the second row) into the column names. After these two steps, the routine steps for data cleaning were employed such as cleaning the column names, converting the data in the `sex` and `apoe4` columns from numeric to character and removing any rows that didn't meet the eligibility criteria (`age_at_onset = .`). The dataset also included the current age of the participant (`current_age`) and years of education (`education`), besides their sex, carrier status for APOE4 and age at onset of MCI.

In total, `r nrow(raw_demo)` participants were recruited, and among these selected individuals, `r nrow(demo)` participants developed MCI.

The average baseline age is `r filter(demo) |> pull(current_age) |> mean() |> round(2)` years.

The proportion of women in the study that are APOE4 carriers is `r round(nrow(filter(demo,sex == "female", apoe4 == "Carrier"))/nrow(filter(demo,sex == "female")), digits = 2)`.

## Import, clean, and tidy the dataset of longitudinally observed biomarker values

```{r}

raw_amyloid = 
  read_csv(file = "./Data/data_mci/mci_amyloid.csv", col_names = FALSE)[-1,] |>
  janitor::row_to_names(1, remove_rows_above = FALSE) |> 
  janitor::clean_names()

amyloid = raw_amyloid |> 
  drop_na() |> 
  rename(id = study_id)
  
```

The same steps for removing the first row and using the second row as the column names for the `demo` dataset was employed for the `amyloid` dataset as well. The original dataset contained missing values in several rows. Before removing the rows with missing values, there were `r nrow(raw_amyloid)` observations in the dataset. After removng the missing values, there are `r nrow(amyloid)` in the dataset. The `amyloid` dataset contains measurements at the baseline, time_2, time_4, time_6, and time_8 for the participants of the study.

## Checking for overlap in participants

```{r}

isolate_demo = 
  anti_join(demo, amyloid, by = "id")

isolate_amyloid =
  anti_join(amyloid, demo, by = "id")
  
```

The number of participants that only appear in the baseline (`demo`) dataset is `r nrow(isolate_demo)`.

The number of participants that only appear in the amyloid (`amyloid`) dataset is `r nrow(isolate_amyloid)`.

## Combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained.

```{r}

demo_amyloid_both = 
  inner_join(demo,amyloid, by = "id")

```

The number of participants that appear in both datasets, baseline and amyloid, is `r nrow(demo_amyloid_both)`.

The average baseline age of the participants is `r filter(demo_amyloid_both) |> pull(current_age) |> mean() |> round(2)` years. 

The proportion of participants that were identified as Carriers for APOE4 is `r round(nrow(filter(demo_amyloid_both, apoe4 == "Carrier"))/nrow(filter(demo_amyloid_both, apoe4 == "Non-carrier")), digits = 2)`.

## Export the result as a CSV to your data directory

```{r}
write_csv(demo_amyloid_both, "data/demo_amyloid_combined.csv")
```

